{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Football Logo Classification - Google Colab Version\n",
    "## Clasificación de logos de equipos de fútbol por liga europea\n",
    "\n",
    "**Dataset:** 605 logos de 26 ligas europeas\n",
    "\n",
    "**Modelos:** CustomCNN (baseline) vs ResNet18 (transfer learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup: Montar Drive e instalar dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Montar Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# Navegar al proyecto\n",
    "import os\n",
    "os.chdir('/content/drive/MyDrive/FLIC')\n",
    "\n",
    "# Instalar dependencias\n",
    "!pip install -q torch torchvision matplotlib seaborn scikit-learn Pillow\n",
    "\n",
    "# Verificar estructura\n",
    "print(\"✓ Drive montado\")\n",
    "print(\"✓ Working directory:\", os.getcwd())\n",
    "print(\"\\n✓ Contenido:\")\n",
    "!ls -la\n",
    "\n",
    "print(\"\\n✓ Módulos src/:\")\n",
    "!ls src/\n",
    "\n",
    "print(\"\\n✓ Primeras 5 ligas en data/:\")\n",
    "!ls data/ | head -5\n",
    "\n",
    "import torch\n",
    "print(\"\\n✓ PyTorch version:\", torch.__version__)\n",
    "print(\"✓ GPU disponible:\", torch.cuda.is_available())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"✓ GPU detectada:\", torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports y configuración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('.')\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.dataset import get_dataloaders\n",
    "from src.models import CustomCNN, get_resnet18\n",
    "from src.train import train_model\n",
    "from src.evaluate import evaluate_model, plot_confusion_matrix, plot_training_history\n",
    "from src.utils import predict_from_dataset, visualize_prediction_from_dataset, visualize_dataset_samples\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cargar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = 'data'\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "train_loader, val_loader, test_loader, class_names = get_dataloaders(\n",
    "    DATA_DIR,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    val_split=0.15,\n",
    "    test_split=0.15\n",
    ")\n",
    "\n",
    "print(f\"Number of classes (leagues): {len(class_names)}\")\n",
    "print(f\"Training samples: {len(train_loader.dataset)}\")\n",
    "print(f\"Validation samples: {len(val_loader.dataset)}\")\n",
    "print(f\"Test samples: {len(test_loader.dataset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explorar ligas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Leagues in dataset:\")\n",
    "for i, league in enumerate(class_names, 1):\n",
    "    print(f\"{i:2d}. {league}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizar muestras del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_dataset_samples(train_loader.dataset.dataset, class_names, n_samples=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenar CustomCNN con múltiples configuraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# SECTION 4: TRAIN CUSTOM CNN WITH MULTIPLE CONFIGURATIONS\n",
    "# ====================================================================\n",
    "# Probamos 3 configuraciones para encontrar la mejor combinación de epochs y lr\n",
    "# Con dataset pequeño (605 imágenes), diferentes configs pueden tener resultados MUY distintos\n",
    "\n",
    "# Configuraciones a probar para CustomCNN (entrena desde cero, sin conocimiento previo):\n",
    "# Config 1 - AGRESIVA: lr alto, pocas epochs\n",
    "#   - Aprende rápido pero puede \"saltar\" el mínimo óptimo\n",
    "#   - Riesgo: overfitting temprano o inestabilidad\n",
    "# Config 2 - BALANCEADA: lr medio, epochs medias  \n",
    "#   - Punto medio entre velocidad y estabilidad\n",
    "#   - Esperamos mejor generalización\n",
    "# Config 3 - CONSERVADORA: lr bajo, más epochs\n",
    "#   - Aprende lento pero converge de forma más estable\n",
    "#   - Menor riesgo de overfitting pero más tiempo de entrenamiento\n",
    "\n",
    "cnn_configs = [\n",
    "    {'name': 'Agresiva', 'epochs': 15, 'lr': 0.001},      # Rápida pero arriesgada\n",
    "    {'name': 'Balanceada', 'epochs': 20, 'lr': 0.0005},   # Punto medio óptimo\n",
    "    {'name': 'Conservadora', 'epochs': 25, 'lr': 0.0001}  # Lenta pero estable\n",
    "]\n",
    "\n",
    "# Guardaremos los resultados de cada configuración para compararlos\n",
    "cnn_results = []\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"CUSTOM CNN - PRUEBA DE CONFIGURACIONES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Probamos cada configuración\n",
    "for i, config in enumerate(cnn_configs, 1):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"CONFIG {i}/3: {config['name']}\")\n",
    "    print(f\"Epochs: {config['epochs']} | Learning Rate: {config['lr']}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Creamos un modelo nuevo para cada configuración (partimos desde cero cada vez)\n",
    "    model = CustomCNN(num_classes=len(class_names))\n",
    "    \n",
    "    # Entrenamos con la configuración actual\n",
    "    history = train_model(\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        epochs=config['epochs'],\n",
    "        lr=config['lr'],\n",
    "        device=DEVICE\n",
    "    )\n",
    "    \n",
    "    # Guardamos los resultados: modelo entrenado + métricas + configuración usada\n",
    "    cnn_results.append({\n",
    "        'config': config,\n",
    "        'model': model,\n",
    "        'history': history,\n",
    "        'final_val_acc': history['val_acc'][-1],  # Accuracy final en validación\n",
    "        'final_val_loss': history['val_loss'][-1],  # Loss final en validación\n",
    "        'overfitting': history['train_acc'][-1] - history['val_acc'][-1]  # Gap train-val (cuanto mayor, más overfitting)\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nResultados Config {config['name']}:\")\n",
    "    print(f\"  - Val Accuracy: {history['val_acc'][-1]:.2f}%\")\n",
    "    print(f\"  - Val Loss: {history['val_loss'][-1]:.4f}\")\n",
    "    print(f\"  - Overfitting (train_acc - val_acc): {history['train_acc'][-1] - history['val_acc'][-1]:.2f}%\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"CUSTOM CNN - Configuraciones completadas\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizar curvas CustomCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos el progreso de entrenamiento de cada configuración del CustomCNN\n",
    "# Esto nos ayuda a identificar overfitting, underfitting, o convergencia óptima\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "fig.suptitle('Custom CNN - Comparación de Configuraciones', fontsize=16, fontweight='bold')\n",
    "\n",
    "for i, result in enumerate(cnn_results):\n",
    "    ax = axes[i]\n",
    "    history = result['history']\n",
    "    config = result['config']\n",
    "    \n",
    "    # Plot de accuracy (train vs validation)\n",
    "    ax.plot(history['train_acc'], label='Train Accuracy', linewidth=2)\n",
    "    ax.plot(history['val_acc'], label='Val Accuracy', linewidth=2)\n",
    "    ax.set_title(f\"{config['name']}\\n(epochs={config['epochs']}, lr={config['lr']})\")\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Accuracy (%)')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seleccionar mejor CustomCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos la mejor configuración del CustomCNN\n",
    "# Criterio: Mayor val_accuracy + menor overfitting (diferencia entre train y val)\n",
    "# No siempre la que mejor va en train es la mejor, puede estar overfitteando\n",
    "\n",
    "best_cnn = max(cnn_results, key=lambda x: x['final_val_acc'] - 0.3 * x['overfitting'])\n",
    "# Penalizamos overfitting con factor 0.3: preferimos modelo que generalice bien\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"MEJOR CONFIGURACIÓN - CUSTOM CNN\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Configuración elegida: {best_cnn['config']['name']}\")\n",
    "print(f\"  - Epochs: {best_cnn['config']['epochs']}\")\n",
    "print(f\"  - Learning Rate: {best_cnn['config']['lr']}\")\n",
    "print(f\"  - Val Accuracy: {best_cnn['final_val_acc']:.2f}%\")\n",
    "print(f\"  - Val Loss: {best_cnn['final_val_loss']:.4f}\")\n",
    "print(f\"  - Overfitting: {best_cnn['overfitting']:.2f}%\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entrenar ResNet18 con múltiples configuraciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# SECTION 5: TRAIN RESNET18 WITH MULTIPLE CONFIGURATIONS\n",
    "# ====================================================================\n",
    "# ResNet18 con transfer learning: YA sabe reconocer patrones de ImageNet (1M imágenes)\n",
    "# Solo necesitamos ajustarlo a nuestras 26 ligas de fútbol\n",
    "\n",
    "# Configuraciones para ResNet18 (transfer learning, pesos preentrenados):\n",
    "# Config 1 - ESTÁNDAR: Configuración típica para transfer learning\n",
    "#   - lr bajo (0.0001) para no destruir los pesos preentrenados de ImageNet\n",
    "#   - Pocas epochs porque ya tiene conocimiento previo\n",
    "# Config 2 - MODERADA: Más refinamiento\n",
    "#   - lr más bajo y más epochs para ajuste más fino\n",
    "# Config 3 - FINA: Máxima precisión\n",
    "#   - lr muy bajo (0.00001) para ajustes mínimos sin romper lo aprendido\n",
    "#   - Más epochs para convergencia lenta pero óptima\n",
    "\n",
    "resnet_configs = [\n",
    "    {'name': 'Estándar', 'epochs': 10, 'lr': 0.0001},    # Transfer learning clásico\n",
    "    {'name': 'Moderada', 'epochs': 15, 'lr': 0.00005},   # Más refinamiento\n",
    "    {'name': 'Fina', 'epochs': 20, 'lr': 0.00001}        # Ajuste ultra-fino\n",
    "]\n",
    "\n",
    "# Guardaremos los resultados de cada configuración\n",
    "resnet_results = []\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"RESNET18 (TRANSFER LEARNING) - PRUEBA DE CONFIGURACIONES\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Probamos cada configuración\n",
    "for i, config in enumerate(resnet_configs, 1):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"CONFIG {i}/3: {config['name']}\")\n",
    "    print(f\"Epochs: {config['epochs']} | Learning Rate: {config['lr']}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    \n",
    "    # Creamos un modelo ResNet18 con pesos de ImageNet\n",
    "    model = get_resnet18(num_classes=len(class_names), pretrained=True)\n",
    "    \n",
    "    # Entrenamos (fine-tuning: ajustamos los pesos preentrenados a nuestro problema)\n",
    "    history = train_model(\n",
    "        model,\n",
    "        train_loader,\n",
    "        val_loader,\n",
    "        epochs=config['epochs'],\n",
    "        lr=config['lr'],\n",
    "        device=DEVICE\n",
    "    )\n",
    "    \n",
    "    # Guardamos resultados\n",
    "    resnet_results.append({\n",
    "        'config': config,\n",
    "        'model': model,\n",
    "        'history': history,\n",
    "        'final_val_acc': history['val_acc'][-1],\n",
    "        'final_val_loss': history['val_loss'][-1],\n",
    "        'overfitting': history['train_acc'][-1] - history['val_acc'][-1]\n",
    "    })\n",
    "    \n",
    "    print(f\"\\nResultados Config {config['name']}:\")\n",
    "    print(f\"  - Val Accuracy: {history['val_acc'][-1]:.2f}%\")\n",
    "    print(f\"  - Val Loss: {history['val_loss'][-1]:.4f}\")\n",
    "    print(f\"  - Overfitting (train_acc - val_acc): {history['train_acc'][-1] - history['val_acc'][-1]:.2f}%\")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"RESNET18 - Configuraciones completadas\")\n",
    "print(f\"{'='*70}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizar curvas ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos el progreso de entrenamiento de cada configuración del ResNet18\n",
    "# Transfer learning suele converger más rápido que entrenar desde cero\n",
    "\n",
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "fig.suptitle('ResNet18 (Transfer Learning) - Comparación de Configuraciones', fontsize=16, fontweight='bold')\n",
    "\n",
    "for i, result in enumerate(resnet_results):\n",
    "    ax = axes[i]\n",
    "    history = result['history']\n",
    "    config = result['config']\n",
    "    \n",
    "    # Plot de accuracy (train vs validation)\n",
    "    ax.plot(history['train_acc'], label='Train Accuracy', linewidth=2)\n",
    "    ax.plot(history['val_acc'], label='Val Accuracy', linewidth=2)\n",
    "    ax.set_title(f\"{config['name']}\\n(epochs={config['epochs']}, lr={config['lr']})\")\n",
    "    ax.set_xlabel('Epoch')\n",
    "    ax.set_ylabel('Accuracy (%)')\n",
    "    ax.legend()\n",
    "    ax.grid(True, alpha=0.3)\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seleccionar mejor ResNet18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seleccionamos la mejor configuración del ResNet18\n",
    "# Mismo criterio: Mayor val_accuracy + menor overfitting\n",
    "\n",
    "best_resnet = max(resnet_results, key=lambda x: x['final_val_acc'] - 0.3 * x['overfitting'])\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"MEJOR CONFIGURACIÓN - RESNET18\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Configuración elegida: {best_resnet['config']['name']}\")\n",
    "print(f\"  - Epochs: {best_resnet['config']['epochs']}\")\n",
    "print(f\"  - Learning Rate: {best_resnet['config']['lr']}\")\n",
    "print(f\"  - Val Accuracy: {best_resnet['final_val_acc']:.2f}%\")\n",
    "print(f\"  - Val Loss: {best_resnet['final_val_loss']:.4f}\")\n",
    "print(f\"  - Overfitting: {best_resnet['overfitting']:.2f}%\")\n",
    "print(\"=\"*70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluar modelos en test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# SECTION 6: EVALUATE MODELS ON TEST SET\n",
    "# ====================================================================\n",
    "# Evaluamos los mejores modelos seleccionados en el test set (datos nunca vistos)\n",
    "# Métricas: accuracy, precision, recall, F1-score por cada liga\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"EVALUACIÓN: MEJOR CUSTOM CNN\")\n",
    "print(\"=\"*70)\n",
    "results_cnn = evaluate_model(best_cnn['model'], test_loader, class_names, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"EVALUACIÓN: MEJOR RESNET18\")\n",
    "print(\"=\"*70)\n",
    "results_resnet = evaluate_model(best_resnet['model'], test_loader, class_names, device=DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparación final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# SECTION 7: FINAL COMPARISON\n",
    "# ====================================================================\n",
    "# Comparamos ambos modelos y determinamos el ganador final\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"COMPARACIÓN FINAL - TEST SET\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Custom CNN ({best_cnn['config']['name']}): {results_cnn['accuracy']:.2f}%\")\n",
    "print(f\"ResNet18 ({best_resnet['config']['name']}): {results_resnet['accuracy']:.2f}%\")\n",
    "print(f\"\\nMejora con Transfer Learning: {results_resnet['accuracy'] - results_cnn['accuracy']:.2f}%\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Seleccionamos el modelo ganador (mayor accuracy en test)\n",
    "if results_resnet['accuracy'] > results_cnn['accuracy']:\n",
    "    winner_name = f\"ResNet18 ({best_resnet['config']['name']})\"\n",
    "    winner_model = best_resnet['model']\n",
    "    winner_results = results_resnet\n",
    "else:\n",
    "    winner_name = f\"Custom CNN ({best_cnn['config']['name']})\"\n",
    "    winner_model = best_cnn['model']\n",
    "    winner_results = results_cnn\n",
    "\n",
    "print(f\"\\nMODELO GANADOR: {winner_name}\")\n",
    "print(f\"Test Accuracy: {winner_results['accuracy']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz de confusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# SECTION 8: CONFUSION MATRIX\n",
    "# ====================================================================\n",
    "# Matriz de confusión del modelo ganador\n",
    "# Muestra dónde el modelo se confunde: qué ligas clasifica mal y con qué las confunde\n",
    "\n",
    "plot_confusion_matrix(\n",
    "    winner_results['labels'],\n",
    "    winner_results['predictions'],\n",
    "    class_names,\n",
    "    figsize=(14, 12)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predicciones de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# SECTION 9: TEST PREDICTIONS\n",
    "# ====================================================================\n",
    "# Probamos el modelo ganador con una imagen aleatoria del test set\n",
    "# Vemos las top-5 predicciones con sus probabilidades\n",
    "\n",
    "import random\n",
    "\n",
    "# Dataset de test (sin transformaciones de augmentation, solo normalización)\n",
    "test_dataset = test_loader.dataset.dataset\n",
    "\n",
    "# Seleccionamos una imagen aleatoria\n",
    "random_idx = random.randint(0, len(test_dataset) - 1)\n",
    "\n",
    "# Hacemos predicción con el modelo ganador\n",
    "predictions, true_label, image = predict_from_dataset(\n",
    "    test_dataset,\n",
    "    winner_model,\n",
    "    class_names,\n",
    "    random_idx,\n",
    "    device=DEVICE,\n",
    "    top_k=5\n",
    ")\n",
    "\n",
    "print(f\"True Label: {true_label}\")\n",
    "print(\"\\nTop 5 predictions:\")\n",
    "for i, (league, prob) in enumerate(predictions, 1):\n",
    "    print(f\"{i}. {league}: {prob:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizamos la predicción (imagen + top 3 predicciones + etiqueta real)\n",
    "visualize_prediction_from_dataset(image, predictions[:3], true_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guardar mejor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ====================================================================\n",
    "# SECTION 10: SAVE BEST MODEL\n",
    "# ====================================================================\n",
    "# Guardamos el modelo ganador para uso futuro\n",
    "\n",
    "import os\n",
    "os.makedirs('models', exist_ok=True)\n",
    "\n",
    "MODEL_PATH = 'models/best_model.pth'\n",
    "torch.save(winner_model.state_dict(), MODEL_PATH)\n",
    "\n",
    "print(\"=\"*70)\n",
    "print(\"MODELO GUARDADO\")\n",
    "print(\"=\"*70)\n",
    "print(f\"Modelo: {winner_name}\")\n",
    "print(f\"Path: {MODEL_PATH}\")\n",
    "print(f\"Test Accuracy: {winner_results['accuracy']:.2f}%\")\n",
    "print(\"=\"*70)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
